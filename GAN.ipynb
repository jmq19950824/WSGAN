{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:22.099577Z",
     "start_time": "2020-08-29T12:05:19.318284Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J3BHjbqDAeK_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#AUCROC,AUCPR,precision,recall,f1-score\n",
    "from sklearn.metrics import roc_curve,auc,average_precision_score,precision_score,recall_score,f1_score\n",
    "\n",
    "#gridsearch/randomsearch\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "#visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.434209Z",
     "start_time": "2020-08-29T12:05:22.106559Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-ARYrELmA6cj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Subset,DataLoader,TensorDataset\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.464145Z",
     "start_time": "2020-08-29T12:05:23.442204Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IpU389GTH915",
    "outputId": "0a87d016-35de-4c1e-90c3-0856015eb39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is off\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  is_cuda=True\n",
    "  print('GPU is on')\n",
    "else:\n",
    "  is_cuda=False\n",
    "  print('GPU is off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.495946Z",
     "start_time": "2020-08-29T12:05:23.472126Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lp22xWtgqQAn"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.543686Z",
     "start_time": "2020-08-29T12:05:23.503795Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "daingP6XH919"
   },
   "outputs": [],
   "source": [
    "def data_prepare(batch_size,contam_ratio,hybrid,seed,contam_val = False):\n",
    "    set_seed(seed)\n",
    "    data = pd.read_csv(\"D:/Jiang/Research_Anomaly Detection/20201030_formal_version/version_tune (if necessary)/CCFD/data/creditcard.csv\")\n",
    "    #change 0,1 label to 1,-1\n",
    "    data.loc[data['Class']==1,'Class'] = -1\n",
    "    data.loc[data['Class']==0,'Class'] = 1\n",
    "\n",
    "    X = data.drop(['Time','Class'], axis=1)\n",
    "    y = data[\"Class\"].values\n",
    "\n",
    "    #split the data to training, validation and testing data (50%,20%,30%)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,shuffle=False)\n",
    "    X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=2/7,shuffle=False)\n",
    "\n",
    "    #the known positive samples before contaminating\n",
    "    known_pos_entire = sum(y_train == -1)\n",
    "    #Minmax\n",
    "    scaler=MinMaxScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    index_contam = np.arange(len(y_train))[y_train == -1]\n",
    "    index_contam = np.random.choice(index_contam,int(contam_ratio*len(index_contam)),replace = False)\n",
    "\n",
    "    y_train[index_contam] = 1\n",
    "    #the known positive samples after contaminating\n",
    "    known_pos_sub = sum(y_train == -1)\n",
    "\n",
    "    print(f'The left true(known) positive samples in the training set:{known_pos_sub}/{known_pos_entire}\\n')\n",
    "    #normal training tensor and dataloader\n",
    "    #none-hybrid model only use \"normal\" samples in the training phase, which could be contaminated\n",
    "    if not hybrid:\n",
    "        index_subset = np.arange(len(y_train))[y_train == 1]\n",
    "    else:\n",
    "        index_subset = np.arange(len(y_train))\n",
    "    \n",
    "\n",
    "    #transform numpy to pytorch tensor\n",
    "    train_tensor = TensorDataset(torch.from_numpy(X_train).float(),torch.tensor(y_train))\n",
    "    train_tensor = Subset(train_tensor,index_subset)\n",
    "    #fitting by batches (using dataloader), there exists randomness when shuffle=True***\n",
    "    train_loader=DataLoader(train_tensor,batch_size=batch_size,shuffle=False,drop_last=True)\n",
    "    \n",
    "    #validation set\n",
    "    X_val_tensor = torch.from_numpy(X_val).float()\n",
    "    #2020.10.16: validation set should also be contaminated\n",
    "    if contam_val:\n",
    "        index_contam_val = np.arange(len(y_val))[y_val == -1]\n",
    "        index_contam_val = np.random.choice(index_contam_val,int(contam_ratio*len(index_contam_val)),replace = False)\n",
    "\n",
    "        y_val[index_contam_val] = 1\n",
    "    \n",
    "    #testing set\n",
    "    X_test_tensor=torch.from_numpy(X_test).float()\n",
    "    \n",
    "    return train_loader,X_val_tensor,y_val,X_test_tensor,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJsqRcy-o6aK"
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "  def __init__(self,input_size,act_fun):\n",
    "    super(generator,self).__init__()\n",
    "\n",
    "    self.encoder_1=nn.Sequential(\n",
    "      nn.Linear(input_size,input_size//4),\n",
    "      act_fun,\n",
    "      )\n",
    "    \n",
    "    self.decoder_1=nn.Sequential(\n",
    "      nn.Linear(input_size//4,input_size),\n",
    "      )\n",
    "\n",
    "    self.encoder_2=nn.Sequential(\n",
    "      nn.Linear(input_size,input_size//4),\n",
    "      act_fun,\n",
    "      )\n",
    "\n",
    "  def forward(self,input):\n",
    "    z=self.encoder_1(input)\n",
    "    X_hat=self.decoder_1(z)\n",
    "    z_hat=self.encoder_2(X_hat)\n",
    "\n",
    "    return z,X_hat,z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.606248Z",
     "start_time": "2020-08-29T12:05:23.585574Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lmxdpdelH92C"
   },
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "  def __init__(self,input_size,act_fun):\n",
    "    super(discriminator,self).__init__()\n",
    "\n",
    "    self.encoder=nn.Sequential(\n",
    "        nn.Linear(input_size,input_size//4),\n",
    "        act_fun,\n",
    "        )\n",
    "\n",
    "    self.classifier=nn.Sequential(\n",
    "        nn.Linear(input_size//4,1),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "  def forward(self,input):\n",
    "    latent_vector = self.encoder(input)\n",
    "    output = self.classifier(latent_vector)\n",
    "\n",
    "    return latent_vector,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.683533Z",
     "start_time": "2020-08-29T12:05:23.644146Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vAfxq0KPH92G"
   },
   "outputs": [],
   "source": [
    "def fit(dataloader,net_generator,net_discriminator,epochs,batch_size,print_loss):\n",
    "  L1_criterion = nn.L1Loss(reduction='mean')\n",
    "  L2_criterion = nn.MSELoss(reduction='mean')\n",
    "  BCE_criterion = nn.BCELoss(reduction='mean')\n",
    "\n",
    "  if is_cuda:\n",
    "    L1_criterion.cuda()\n",
    "    L2_criterion.cuda()\n",
    "    BCE_criterion.cuda()\n",
    "\n",
    "  loss_D_list = []\n",
    "  loss_G_list = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    for i,data in enumerate(dataloader):\n",
    "      X,_ = data\n",
    "      y_real = torch.FloatTensor(batch_size).fill_(0)#real label=0,size=batch_size\n",
    "      y_fake = torch.FloatTensor(batch_size).fill_(1)#fake label=1,size=batch_size\n",
    "\n",
    "      if is_cuda:\n",
    "        X = X.cuda()\n",
    "        y_real = y_real.cuda()\n",
    "        y_fake = y_fake.cuda()\n",
    "\n",
    "      X = Variable(X)\n",
    "      y_real = Variable(y_real)\n",
    "      y_fake = Variable(y_fake)\n",
    "\n",
    "      #zero grad for discriminator\n",
    "      net_discriminator.zero_grad()\n",
    "      #training the discriminator with real sample\n",
    "      _,output = net_discriminator(X)\n",
    "      loss_D_real = BCE_criterion(output.view(-1),y_real)\n",
    "\n",
    "      #training the discriminator with fake sample\n",
    "      _,X_hat,_ = net_generator(X)\n",
    "      _,output = net_discriminator(X_hat)\n",
    "\n",
    "      loss_D_fake = BCE_criterion(output.view(-1),y_fake)\n",
    "\n",
    "      #entire loss in discriminator\n",
    "      loss_D = (loss_D_real+loss_D_fake)/2\n",
    "      \n",
    "      loss_D.backward()\n",
    "      optimizer_D.step()\n",
    "\n",
    "      #training the generator based on the result from the discriminator\n",
    "      net_generator.zero_grad()\n",
    "\n",
    "      z,X_hat,z_hat = net_generator(X)\n",
    "\n",
    "      #latent loss\n",
    "      feature_real,_ = net_discriminator(X)\n",
    "      feature_fake,_ = net_discriminator(X_hat)\n",
    "\n",
    "      loss_G_latent = L2_criterion(feature_fake,feature_real)\n",
    "      \n",
    "      #contexutal loss\n",
    "      loss_G_contextual = L1_criterion(X,X_hat)\n",
    "      #entire loss in generator\n",
    "\n",
    "      #encoder loss\n",
    "      loss_G_encoder = L1_criterion(z,z_hat)\n",
    "      \n",
    "      loss_G = (loss_G_latent + loss_G_contextual + loss_G_encoder)/3\n",
    "      \n",
    "      loss_G.backward()\n",
    "      optimizer_G.step()\n",
    "\n",
    "      if (i%50 == 0) & print_loss:\n",
    "        print('[%d/%d] [%d/%d] Loss D: %.4f / Loss G: %.4f' % (epoch+1,epochs,i,len(dataloader),loss_D,loss_G))\n",
    "\n",
    "      loss_D_list.append(loss_D)\n",
    "      loss_G_list.append(loss_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.714448Z",
     "start_time": "2020-08-29T12:05:23.692520Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Fj4vBMyiH92I"
   },
   "outputs": [],
   "source": [
    "def evaluation(data_tensor,model):\n",
    "  if is_cuda:\n",
    "    data_tensor = data_tensor.cuda()\n",
    "    \n",
    "  z,_,z_hat = model(data_tensor)\n",
    "\n",
    "  L1_criterion = nn.L1Loss(reduction='none')\n",
    "  score = L1_criterion(z,z_hat)\n",
    "  score = torch.sum(score,dim=1).cpu().detach().numpy()\n",
    "    \n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kH-YW-DiH92K"
   },
   "source": [
    "Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFlOSWWoR-8_"
   },
   "outputs": [],
   "source": [
    "seed_pool = [1,2,3,4,5]\n",
    "anomaly_ratio_pool = [0.001,0.002,0.003]\n",
    "# contam_ratio_pool = [0.98,0.9,0.5]\n",
    "contam_ratio_pool = [1.0,0.0]\n",
    "\n",
    "#random search size\n",
    "search_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T12:05:23.745364Z",
     "start_time": "2020-08-29T12:05:23.721430Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tlGeKMprH92L"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "hyper_act_fun = [nn.Tanh(),nn.LeakyReLU()]\n",
    "hyper_lr=[1e-2,1e-3,1e-4]\n",
    "hyper_mom=[0.5,0.7,0.9]\n",
    "\n",
    "hyper_list_entire = list(product(hyper_act_fun,hyper_lr,hyper_mom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyk8ahDD9Sty"
   },
   "outputs": [],
   "source": [
    "def random_search(hyper_list_entire,search_size,seed):\n",
    "  if search_size < len(hyper_list_entire):\n",
    "    set_seed(seed)\n",
    "    index = np.random.choice(np.arange(len(hyper_list_entire)),search_size,replace = False)\n",
    "\n",
    "    hyper_list = []\n",
    "    for i in index:\n",
    "      hyper_list.append(hyper_list_entire[i])\n",
    "  else:\n",
    "    hyper_list = hyper_list_entire\n",
    "\n",
    "  return hyper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "nnKc-wjASCTh",
    "outputId": "fa53f18c-7790-409c-c5b9-a5ded34d796d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.3949\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5158\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.661\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7273\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6859\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.426\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4729\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5604\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5094\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6714\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (Tanh(), 0.01, 0.9)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 52.33\n",
      "Recall: 41.67\n",
      "F1-score: 46.39\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 36.84\n",
      "Recall: 58.33\n",
      "F1-score: 45.16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 30.74\n",
      "Recall: 73.15\n",
      "F1-score: 43.29\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████                                                                | 1/5 [32:25<2:09:41, 1945.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6581\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4319\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6501\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5184\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6706\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5567\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.3974\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4966\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6642\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4039\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 46.51\n",
      "Recall: 37.04\n",
      "F1-score: 41.24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 35.09\n",
      "Recall: 55.56\n",
      "F1-score: 43.01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 29.57\n",
      "Recall: 70.37\n",
      "F1-score: 41.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|███████████████████████████████▏                                              | 2/5 [1:04:54<1:37:19, 1946.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.2983\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5976\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6797\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7763\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5136\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7195\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4127\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4259\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6798\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.01621\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 66.28\n",
      "Recall: 52.78\n",
      "F1-score: 58.76\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 44.44\n",
      "Recall: 70.37\n",
      "F1-score: 54.48\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 31.52\n",
      "Recall: 75.0\n",
      "F1-score: 44.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████████████████████████████████████████████▊                               | 3/5 [1:37:17<1:04:50, 1945.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4647\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6322\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4697\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6513\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.669\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7094\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4811\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5346\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4598\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.544\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (Tanh(), 0.01, 0.5)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 45.35\n",
      "Recall: 36.11\n",
      "F1-score: 40.21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 35.09\n",
      "Recall: 55.56\n",
      "F1-score: 43.01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 29.57\n",
      "Recall: 70.37\n",
      "F1-score: 41.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [2:09:40<32:24, 1944.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7507\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7357\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.1913\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.736\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5231\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6532\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6704\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4448\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6473\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.9)\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5422\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (Tanh(), 0.001, 0.9)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:0/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 54.65\n",
      "Recall: 43.52\n",
      "F1-score: 48.45\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 41.52\n",
      "Recall: 65.74\n",
      "F1-score: 50.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 30.74\n",
      "Recall: 73.15\n",
      "F1-score: 43.29\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [2:31:28<2:31:28, 9088.63s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.3966\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5291\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6694\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7795\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7125\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4298\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4738\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5731\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5552\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.724\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (Tanh(), 0.01, 0.9)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 70.93\n",
      "Recall: 56.48\n",
      "F1-score: 62.89\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 47.95\n",
      "Recall: 75.93\n",
      "F1-score: 58.78\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 32.68\n",
      "Recall: 77.78\n",
      "F1-score: 46.03\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████                                                                | 1/5 [18:23<1:13:33, 1103.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6922\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4638\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6504\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6194\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7174\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6145\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4168\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.628\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.667\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4087\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 54.65\n",
      "Recall: 43.52\n",
      "F1-score: 48.45\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 44.44\n",
      "Recall: 70.37\n",
      "F1-score: 54.48\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 31.52\n",
      "Recall: 75.0\n",
      "F1-score: 44.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▊                                                 | 2/5 [36:51<55:14, 1104.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.2927\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7318\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7232\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.779\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5268\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7291\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4141\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4277\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.69\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.3284\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (LeakyReLU(negative_slope=0.01), 0.001, 0.9)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 67.44\n",
      "Recall: 53.7\n",
      "F1-score: 59.79\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 45.03\n",
      "Recall: 71.3\n",
      "F1-score: 55.2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 31.52\n",
      "Recall: 75.0\n",
      "F1-score: 44.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [55:08<36:44, 1102.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.466\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6404\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4729\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5154\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6763\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7313\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4843\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5488\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4687\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5654\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (Tanh(), 0.01, 0.5)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 51.16\n",
      "Recall: 40.74\n",
      "F1-score: 45.36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 40.35\n",
      "Recall: 63.89\n",
      "F1-score: 49.46\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 30.74\n",
      "Recall: 73.15\n",
      "F1-score: 43.29\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [1:13:33<18:23, 1103.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7614\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7539\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7671\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7655\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.01, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.7471\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.0001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6544\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (LeakyReLU(negative_slope=0.01), 0.001, 0.5)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6727\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.4469\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.001, 0.7)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.6566\n",
      "******************************\n",
      "\n",
      "\n",
      "Finding Optimal Hyper-parameters......Current Candidates: (Tanh(), 0.0001, 0.9)\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "The metric value corresponded to the hyper-parameters is :0.5475\n",
      "******************************\n",
      "\n",
      "\n",
      "The best hyper-parameters are: (LeakyReLU(negative_slope=0.01), 0.01, 0.7)\n",
      "\n",
      "\n",
      "Testing Phrase......\n",
      "The left true(known) positive samples in the training set:269/269\n",
      "\n",
      "\n",
      "\n",
      "Precision: 58.14\n",
      "Recall: 46.3\n",
      "F1-score: 51.55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 46.78\n",
      "Recall: 74.07\n",
      "F1-score: 57.35\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 32.3\n",
      "Recall: 76.85\n",
      "F1-score: 45.48\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [4:03:18<00:00, 8015.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for contam_ratio in tqdm(contam_ratio_pool):  \n",
    "  df_result = pd.DataFrame(data = None,index = ['AUCPR'] + anomaly_ratio_pool,columns = seed_pool)\n",
    "  for seed in tqdm(seed_pool):\n",
    "    #############################################seleting the best hyper-parameters in validation set#############################################\n",
    "    metric_value_list=list()\n",
    "    hyper_list = random_search(hyper_list_entire,search_size,seed)\n",
    "    for i in range(len(hyper_list)):\n",
    "      try:\n",
    "        print(f'Finding Optimal Hyper-parameters......Current Candidates: {hyper_list[i]}')\n",
    "        act_fun,lr,mom = hyper_list[i]\n",
    "        #data\n",
    "        train_loader,X_val_tensor,y_val,_,_ = data_prepare(batch_size,contam_ratio,hybrid = False,seed = seed)\n",
    "        #model initialization\n",
    "        set_seed(seed)\n",
    "        net_generator=generator(input_size = X_val_tensor.size(1),act_fun = act_fun)\n",
    "        net_discriminator=discriminator(input_size = X_val_tensor.size(1),act_fun = act_fun)\n",
    "\n",
    "        if is_cuda:\n",
    "          net_generator.cuda()\n",
    "          net_discriminator.cuda()\n",
    "\n",
    "        optimizer_G=torch.optim.SGD(net_generator.parameters(),lr = lr,momentum = mom)\n",
    "        optimizer_D=torch.optim.SGD(net_discriminator.parameters(),lr = lr,momentum = mom)\n",
    "        #fitting\n",
    "        fit(dataloader = train_loader,net_generator = net_generator,net_discriminator = net_discriminator,\n",
    "          epochs = epochs,batch_size = batch_size,print_loss = False)\n",
    "        \n",
    "        #evaluation\n",
    "        score = evaluation(data_tensor = X_val_tensor,model = net_generator)\n",
    "        metric_value = average_precision_score(y_true = y_val,y_score = score,pos_label = -1)\n",
    "        #metric_value = np.std(score)\n",
    "        metric_value_list.append(metric_value)\n",
    "\n",
    "        print(f'The metric value corresponded to the hyper-parameters is :{metric_value:{.4}}')\n",
    "        print('******************************')\n",
    "        print('\\n')\n",
    "      except:\n",
    "        #keep the right index\n",
    "        metric_value_list.append(0)\n",
    "        pass\n",
    "      continue\n",
    "\n",
    "    best_hyper_params=hyper_list[metric_value_list.index(max(metric_value_list))]\n",
    "    print(f'The best hyper-parameters are: {best_hyper_params}')\n",
    "    print('\\n')\n",
    "    ###################################################################testing#########################################################################\n",
    "    print('Testing Phrase......')\n",
    "    act_fun,lr,mom = best_hyper_params\n",
    "\n",
    "    #data\n",
    "    train_loader,_,_,X_test_tensor,y_test = data_prepare(batch_size,contam_ratio,hybrid = False,seed = seed)\n",
    "    \n",
    "    #model initialization, there exists randomness because of weight initialization***\n",
    "    set_seed(seed)\n",
    "    net_generator=generator(input_size = X_test_tensor.size(1),act_fun = act_fun)\n",
    "    net_discriminator=discriminator(input_size = X_test_tensor.size(1),act_fun = act_fun)\n",
    "\n",
    "    if is_cuda:\n",
    "      net_generator.cuda()\n",
    "      net_discriminator.cuda()\n",
    "\n",
    "    optimizer_G = torch.optim.SGD(net_generator.parameters(),lr = lr,momentum = mom)\n",
    "    optimizer_D = torch.optim.SGD(net_discriminator.parameters(),lr = lr,momentum = mom)\n",
    "    #fitting\n",
    "    fit(dataloader = train_loader,net_generator = net_generator,net_discriminator = net_discriminator,\n",
    "      epochs = epochs,batch_size = batch_size,print_loss = False)\n",
    "    #evaluation\n",
    "    score = evaluation(data_tensor = X_test_tensor,model = net_generator)\n",
    "    \n",
    "    #store the result\n",
    "    #AUCPR\n",
    "    df_result.loc['AUCPR',seed] = average_precision_score(y_true = y_test,y_score = score,pos_label = -1)\n",
    "    #F1\n",
    "    for anomaly_ratio in anomaly_ratio_pool:\n",
    "        threshold = score[np.argsort(-score)][int(anomaly_ratio*len(score))]\n",
    "        \n",
    "        y_pred = np.ones(len(score))\n",
    "        y_pred[score >= threshold] = -1\n",
    "        \n",
    "        print('\\n')\n",
    "        print(f'Precision: {round(precision_score(y_pred = y_pred, y_true = y_test, pos_label= -1)*100,2)}')\n",
    "        print(f'Recall: {round(recall_score(y_pred = y_pred, y_true = y_test, pos_label= -1)*100,2)}')\n",
    "        print(f'F1-score: {round(f1_score(y_pred = y_pred, y_true = y_test, pos_label= -1)*100,2)}')\n",
    "        print('\\n')\n",
    "\n",
    "        df_result.loc[anomaly_ratio,seed] = f1_score(y_pred = y_pred,y_true = y_test,pos_label = -1)\n",
    "\n",
    "  #mean & sd\n",
    "  df_result['mean'] = np.mean(df_result.loc[:,seed_pool],axis = 1)\n",
    "  df_result['std'] = np.std(df_result.loc[:,seed_pool],axis = 1)\n",
    "  df_result = round(df_result.astype('float64')*100,2)\n",
    "\n",
    "  file_path = 'D:/Jiang/Research_Anomaly Detection/20201030_formal_version/version_tune (if necessary)/CCFD/result/' + 'CCFD_GAN_' + str(contam_ratio) + '.csv'\n",
    "  df_result.to_csv(file_path,index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CCFD_GAN_tuneloop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
